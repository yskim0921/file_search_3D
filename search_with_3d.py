# search_with_3d.py (ê¸°ì¡´ êµ¬ì¡° + 3D ì‹œê°í™”)

import streamlit as st
import numpy as np
import plotly.graph_objects as go
from typing import TypedDict, List
from langchain import PromptTemplate
from langchain_community.llms import Ollama
from langchain.chains import LLMChain
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OllamaEmbeddings
from langchain_core.documents import Document
from langgraph.graph import StateGraph, END
import pymysql

# ğŸ”§ ìˆ˜ì •: ìƒíƒœ ì •ì˜ì— ë²¡í„° ì •ë³´ ì¶”ê°€
class AgentState(TypedDict):
    query: str
    keywords: str
    file_paths: list
    relevant_docs: str
    result: str
    search_vectors: list  # 3D ì‹œê°í™”ìš© ë²¡í„° ë°ì´í„° ì¶”ê°€

# DB ì ‘ì† ì •ë³´
DB_CONFIG = {
    'host': 'localhost',
    'user': 'admin',
    'password': '1qazZAQ!',
    'db': 'final',
    'charset': 'utf8mb4'
}

# PCA í•¨ìˆ˜
def robust_pca(X, n_components=3):
    try:
        X = np.array(X, dtype=np.float64)
        if X.shape[0] < 2:
            return X
        X_mean = np.mean(X, axis=0)
        X_centered = X - X_mean
        U, s, Vt = np.linalg.svd(X_centered, full_matrices=False)
        n_components = min(n_components, X_centered.shape[1], X_centered.shape[0])
        V = Vt[:n_components].T
        X_reduced = X_centered @ V
        return np.real(X_reduced)
    except Exception as e:
        st.error(f"PCA ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
        return X[:, :min(3, X.shape[1])] if X.shape[1] >= 2 else np.column_stack([X.flatten(), np.zeros(X.shape[0]), np.zeros(X.shape[0])])

# Streamlit ì„¤ì •
st.set_page_config(page_title="ğŸ” ë¬¸ì„œ ê²€ìƒ‰ & 3D ì‹œê°í™”", layout="wide")
st.title("ğŸ” ë¬¸ì„œ ê²€ìƒ‰ & 3D ì‹œê°í™”")

# ìºì‹œëœ ë¦¬ì†ŒìŠ¤
@st.cache_resource
def get_llm():
    return Ollama(model="exaone3.5:2.4b")

@st.cache_resource
def get_embeddings():
    return OllamaEmbeddings(model="exaone3.5:2.4b")

llm = get_llm()
embeddings = get_embeddings()

# í‚¤ì›Œë“œ ì¶”ì¶œ ì—ì´ì „íŠ¸ (ê¸°ì¡´ê³¼ ë™ì¼)
keyword_prompt = PromptTemplate.from_template(
    """ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ ë„ì–´ì“°ê¸° í™•ì¸í•˜ê³  ì°¾ê³ ì í•˜ëŠ” í‚¤ì›Œë“œë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì¶œë ¥í•˜ì„¸ìš”.
    ë²¡í„°ìŠ¤í† ì–´ ê²€ìƒ‰ì„ ìœ„í•œ ìµœì ì˜ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
    \nì§ˆë¬¸: {query}"""
)

def extractor_agent(state: AgentState):
    chain = LLMChain(llm=llm, prompt=keyword_prompt)
    keywords = chain.run({"query": state["query"]})
    return {**state, "keywords": keywords.strip()}

# ğŸ”§ ìˆ˜ì •: RAG + íŒŒì¼ ì •ë³´ + ë²¡í„° ì •ë³´ ì¶”ì¶œ ì—ì´ì „íŠ¸
def rag_agent(state: AgentState):
    vectorstore = Chroma(
        persist_directory="./rag_chroma/documents/summary/", 
        embedding_function=embeddings
    )
    
    # ë²¡í„°ìŠ¤í† ì–´ ê²€ìƒ‰ (ì ìˆ˜ í¬í•¨) - ê¸°ì¡´ê³¼ ë™ì¼
    results = vectorstore.similarity_search_with_score(state["keywords"], k=10)
    
    if not results:
        return {
            **state,
            "file_paths": [],
            "relevant_docs": "",
            "search_vectors": []
        }
    
    # ì ìˆ˜ ë²”ìœ„ ê³„ì‚° - ê¸°ì¡´ê³¼ ë™ì¼
    scores = [score for _, score in results]
    min_score = min(scores)
    max_score = max(scores)
    
    # ğŸ”§ ì¶”ê°€: ì¿¼ë¦¬ ë²¡í„° ìƒì„±
    query_vector = embeddings.embed_query(state["keywords"])
    search_vectors = []
    
    # MySQL ì—°ê²° ë° íŒŒì¼ ì •ë³´ ì¡°íšŒ - ê¸°ì¡´ê³¼ ë™ì¼
    conn = None
    file_entries = []
    try:
        conn = pymysql.connect(**DB_CONFIG)
        cursor = conn.cursor()
        
        for doc, score in results:
            # ğŸ”§ ê¸°ì¡´ ìœ ì‚¬ë„ ê³„ì‚° ë¡œì§ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            if max_score == min_score:
                similarity = 100.0
            else:
                similarity = (1 - (score - min_score)/(max_score - min_score)) * 100
            
            # ë¬¸ì„œ ID ì¶”ì¶œ
            doc_id = doc.metadata.get('id')
            
            # ğŸ”§ ì¶”ê°€: ë¬¸ì„œ ë²¡í„° ìƒì„± (3D ì‹œê°í™”ìš©)
            doc_text = doc.page_content
            try:
                doc_vector = embeddings.embed_query(doc_text[:1000])  # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
                search_vectors.append({
                    'vector': doc_vector,
                    'text': doc_text[:200],
                    'similarity': similarity,
                    'doc_id': doc_id,
                    'is_query': False
                })
            except:
                continue
            
            # MySQLì—ì„œ íŒŒì¼ ì •ë³´ ì¡°íšŒ - ê¸°ì¡´ê³¼ ë™ì¼
            if doc_id:
                cursor.execute("""
                    SELECT file_name, file_location, summary 
                    FROM documents 
                    WHERE id = %s
                """, (doc_id,))
                row = cursor.fetchone()
                if row:
                    # ğŸ”§ ì¶”ê°€: ë²¡í„° ë°ì´í„°ì— íŒŒì¼ ì •ë³´ ì¶”ê°€
                    if search_vectors:
                        search_vectors[-1]['file_name'] = row[0]
                        search_vectors[-1]['file_location'] = row[1]
                        search_vectors[-1]['full_summary'] = row[2]
                    
                    file_entries.append({
                        'name': row[0],
                        'location': row[1],
                        'summary': row[2],  # ì „ì²´ ìš”ì•½ ì €ì¥
                        'relevance': round(similarity, 1)
                    })
    except Exception as e:
        st.error(f"DB ì˜¤ë¥˜: {e}")
    finally:
        if conn: 
            conn.close()
    
    # ğŸ”§ ì¶”ê°€: ì¿¼ë¦¬ ë²¡í„°ë„ ì¶”ê°€
    search_vectors.append({
        'vector': query_vector,
        'text': f"ê²€ìƒ‰ ì¿¼ë¦¬: {state['keywords']}",
        'similarity': 100.0,
        'doc_id': 'QUERY',
        'is_query': True
    })
    
    # ë¬¸ì„œ ìš”ì•½ ìƒì„± - ê¸°ì¡´ê³¼ ë™ì¼
    doc_summary = "\n".join([d.page_content for d, _ in results])
    
    return {
        **state, 
        "file_paths": file_entries, 
        "relevant_docs": doc_summary,
        "search_vectors": search_vectors  # ğŸ”§ ì¶”ê°€
    }

# ìµœì¢… ë‹µë³€ ì—ì´ì „íŠ¸ - ê¸°ì¡´ê³¼ ë™ì¼
answer_prompt = PromptTemplate.from_template(
    """
    --- ì œê³µëœ ì •ë³´ ---
    ì§ˆë¬¸: {query}
    í‚¤ì›Œë“œ: {keywords}
    ë¬¸ì„œ ìš”ì•½:
    {relevant_docs}
    íŒŒì¼ ê²½ë¡œ:
    {file_paths}
    
    âš ï¸ ì ˆëŒ€ ì§€ì–´ë‚´ê±°ë‚˜ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.
    ì œê³µëœ ì •ë³´ ì•ˆì— ì—†ìœ¼ë©´ " ê´€ë ¨ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"ë¼ê³ ë§Œ ë‹µë³€í•˜ì„¸ìš”.

    ì¶œë ¥ ê·œì¹™:
    ê° íŒŒì¼ì— ëŒ€í•´ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì •í™•íˆ ì¶œë ¥í•˜ì„¸ìš”:
    # íŒŒì¼ëª…: [íŒŒì¼ëª…]
    # íŒŒì¼ìœ„ì¹˜: [íŒŒì¼ ì „ì²´ ê²½ë¡œ]
    # ê´€ë ¨ì„±: [ì†Œìˆ˜ì  1ìë¦¬ %]
    # ì„¤ëª…: [ë¬¸ì„œ ìš”ì•½]

    ê´€ë ¨ ì •ë³´ê°€ ì—†ìœ¼ë©´ " ê´€ë ¨ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"
    """
)

def answer_agent(state: AgentState):
    entries = state.get("file_paths", [])
    if not entries:
        return {**state, "result": " ê´€ë ¨ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"}
    
    answer = ""
    for i, entry in enumerate(entries, 1):
        answer += f"{i}ìˆœìœ„\n"
        answer += f"# íŒŒì¼ëª…: {entry['name']}\n"
        answer += f"# íŒŒì¼ìœ„ì¹˜: {entry['location']}\n"
        answer += f"# ê´€ë ¨ì„±: {entry['relevance']}%\n"
        answer += f"# ì„¤ëª…: {entry['summary']}\n\n"  # ğŸ”§ ìˆ˜ì •: ì „ì²´ ìš”ì•½ í‘œì‹œ
    
    return {**state, "result": answer.strip()}

# LangGraph ì—°ê²° - ê¸°ì¡´ê³¼ ë™ì¼
graph = StateGraph(AgentState)
graph.add_node("extractor", extractor_agent)
graph.add_node("rag", rag_agent)
graph.add_node("answer", answer_agent)
graph.set_entry_point("extractor")
graph.add_edge("extractor", "rag")
graph.add_edge("rag", "answer")
graph.add_edge("answer", END)
app = graph.compile()

# ğŸ”§ ìƒˆë¡œìš´ ë¶€ë¶„: Streamlit UI
st.sidebar.header("âš™ï¸ ì„¤ì •")
query = st.sidebar.text_input("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", value="ì—ì´ë‹·ë¹„ì§€")

if st.sidebar.button("ğŸ” ê²€ìƒ‰ ì‹¤í–‰", type="primary"):
    if query:
        with st.spinner("ê²€ìƒ‰ ì¤‘..."):
            # ğŸ”§ ê¸°ì¡´ LangGraph íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            state = {
                "query": query, 
                "keywords": "", 
                "file_paths": [], 
                "relevant_docs": "", 
                "result": "",
                "search_vectors": []  # ğŸ”§ ì¶”ê°€
            }
            result = app.invoke(state)
            
            # ì„¸ì…˜ ìƒíƒœì— ê²°ê³¼ ì €ì¥
            st.session_state.search_result = result
    else:
        st.sidebar.error("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# ê²°ê³¼ í‘œì‹œ
if 'search_result' in st.session_state:
    result = st.session_state.search_result
    
    # 2ì—´ ë ˆì´ì•„ì›ƒ
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("ğŸ“„ ê²€ìƒ‰ ê²°ê³¼")
        
        # ğŸ”§ ê¸°ì¡´ í…ìŠ¤íŠ¸ ê²°ê³¼ í‘œì‹œ
        st.text_area(
            "ê²€ìƒ‰ ê²°ê³¼ (ê¸°ì¡´ í˜•ì‹)",
            value=result["result"],
            height=500,
            key="text_result"
        )
        
        # ì¶”ê°€ ì •ë³´
        if result.get("file_paths"):
            st.subheader("ğŸ“Š ìš”ì•½ ì •ë³´")
            st.metric("ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜", len(result["file_paths"]))
            if result["file_paths"]:
                avg_relevance = sum(item['relevance'] for item in result["file_paths"]) / len(result["file_paths"])
                st.metric("í‰ê·  ê´€ë ¨ì„±", f"{avg_relevance:.1f}%")
    
    with col2:
        st.subheader("ğŸŒŒ 3D ì‹œê°í™”")
        
        # ğŸ”§ 3D ì‹œê°í™”
        if result.get("search_vectors") and len(result["search_vectors"]) > 1:
            try:
                # ë²¡í„° ë°ì´í„° ì¤€ë¹„
                valid_vectors = []
                valid_items = []
                
                for item in result["search_vectors"]:
                    if 'vector' in item and isinstance(item['vector'], list):
                        try:
                            vector_array = np.array(item['vector'], dtype=np.float64)
                            if not np.isnan(vector_array).any():
                                valid_vectors.append(vector_array)
                                valid_items.append(item)
                        except:
                            continue
                
                if len(valid_vectors) >= 2:
                    vectors = np.array(valid_vectors)
                    vectors_3d = robust_pca(vectors, n_components=3)
                    
                    # ì‹œê°í™” ë°ì´í„° ì¤€ë¹„
                    colors = []
                    sizes = []
                    texts = []
                    symbols = []
                    
                    for item in valid_items:
                        if item['is_query']:
                            colors.append('red')
                            sizes.append(20)
                            symbols.append('diamond')
                            texts.append(f"ğŸ” {item['text']}")
                        else:
                            similarity = item['similarity']
                            green_val = max(0, min(255, int(similarity * 2.55)))
                            red_val = max(0, min(255, 255 - green_val))
                            colors.append(f'rgb({red_val}, {green_val}, 100)')
                            sizes.append(max(8, 10 + similarity/10))
                            symbols.append('circle')
                            
                            file_name = item.get('file_name', 'Unknown')
                            summary = item.get('full_summary', item['text'])[:300]
                            texts.append(f"{file_name}<br>ìœ ì‚¬ë„: {similarity:.1f}%<br>{summary}")
                    
                    # Plotly 3D ê·¸ë˜í”„
                    fig = go.Figure()
                    
                    # ì ë“¤ ì¶”ê°€
                    for i in range(len(vectors_3d)):
                        fig.add_trace(go.Scatter3d(
                            x=[float(vectors_3d[i, 0])],
                            y=[float(vectors_3d[i, 1])],
                            z=[float(vectors_3d[i, 2])],
                            mode='markers',
                            marker=dict(
                                size=sizes[i],
                                color=colors[i],
                                symbol=symbols[i],
                                line=dict(width=2, color='DarkSlateGrey'),
                                opacity=0.9 if valid_items[i]['is_query'] else 0.7
                            ),
                            text=texts[i],
                            hoverinfo='text',
                            showlegend=False,
                            name=f"Document {i}"
                        ))
                    
                    # ì—°ê²°ì„  ì¶”ê°€
                    query_idx = len(vectors_3d) - 1
                    for i in range(len(vectors_3d) - 1):
                        fig.add_trace(go.Scatter3d(
                            x=[float(vectors_3d[query_idx, 0]), float(vectors_3d[i, 0])],
                            y=[float(vectors_3d[query_idx, 1]), float(vectors_3d[i, 1])],
                            z=[float(vectors_3d[query_idx, 2]), float(vectors_3d[i, 2])],
                            mode='lines',
                            line=dict(color='lightgray', width=2, dash='dot'),
                            opacity=0.4,
                            showlegend=False,
                            hoverinfo='skip'
                        ))
                    
                    fig.update_layout(
                        title="ê²€ìƒ‰ ê²°ê³¼ì˜ 3D ë²¡í„° ê³µê°„",
                        scene=dict(
                            xaxis_title="ì£¼ì œ ìœ ì‚¬ì„±",
                            yaxis_title="ì˜ë¯¸ì  ë³µì¡ë„",
                            zaxis_title="ë¬¸ë§¥ ê´€ë ¨ì„±",
                            camera=dict(eye=dict(x=1.5, y=1.5, z=1.5)),
                            aspectmode='cube'
                        ),
                        height=500,
                        showlegend=False,
                        margin=dict(l=0, r=0, t=40, b=0)
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # ë²”ë¡€
                    st.markdown("""
                    **ì‹œê°í™” ì„¤ëª…:**
                    - ğŸ”¶ ë¹¨ê°„ ë‹¤ì´ì•„ëª¬ë“œ: ê²€ìƒ‰ ì¿¼ë¦¬
                    - ğŸŸ¢ ì´ˆë¡ìƒ‰ ì : ë†’ì€ ìœ ì‚¬ë„ ë¬¸ì„œ  
                    - ğŸ”µ íŒŒë€ìƒ‰ ì : ë‚®ì€ ìœ ì‚¬ë„ ë¬¸ì„œ
                    - ì ì„ : ì¿¼ë¦¬ì™€ ë¬¸ì„œ ê°„ ì—°ê²°
                    """)
                else:
                    st.warning("ì‹œê°í™”í•  ë²¡í„° ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                    
            except Exception as e:
                st.error(f"3D ì‹œê°í™” ì˜¤ë¥˜: {str(e)}")
        else:
            st.info("ê²€ìƒ‰ì„ ì‹¤í–‰í•˜ë©´ 3D ì‹œê°í™”ê°€ í‘œì‹œë©ë‹ˆë‹¤.")

# ğŸ”§ ì½˜ì†” ì¶œë ¥ë„ ìœ ì§€ (ê¸°ì¡´ ë°©ì‹)
if st.sidebar.button("ğŸ–¥ï¸ ì½˜ì†” ì‹¤í–‰ (ê¸°ì¡´ ë°©ì‹)"):
    query = "ì—ì´ë‹·ë¹„ì§€"
    state = {"query": query, "keywords": "", "file_paths": [], "relevant_docs": "", "result": "", "search_vectors": []}
    result = app.invoke(state)
    st.sidebar.code(result["result"])

# ì´ˆê¸°í™” ë²„íŠ¼
if st.sidebar.button("ğŸ”„ ì´ˆê¸°í™”"):
    if 'search_result' in st.session_state:
        del st.session_state.search_result
    st.rerun()